---
title: "Lecture 10: Bootstrap"
subtitle: "STAT 324"
author: "Ralph Trane"
institute: "University of Wisconsin--Madison<br><br>"
date: "Spring 2020"
output:
  xaringan::moon_reader:
    self_contained: true
    css: [../css/uwmadison.css, default-fonts, ../css/extra-classes.css]
    lib_dir: libs
    nature:
      titleSlideClass: [center, top, .title-slide]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ration: '16:9'
      navigation:
        scroll: false
---

```{r echo = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = T, warning = FALSE, message = FALSE,
                      dpi = 300, fig.align = 'center',
                      fig.width = 4, fig.height = 3, 
                      out.width = "400px", out.height = "300px"
                      )
library(tidyverse); library(distributions3)
theme_set(theme_bw())
set.seed(090539)
```


# Confidence Interval: The Short Story


---
layout: true

# Bootstrap

---

To find confidence interval, we use the distribution of $\frac{\bar{X} - E(\bar{X})}{\text{SD}(\bar{X})}$. 

If $\bar{X} \sim N$, and $\text{SD}(\bar{X})$ is known, then $\frac{\bar{X} - E(\bar{X})}{\text{SD}(\bar{X})} \sim N$.

If $\bar{X} \sim N$, and $\text{SD}(\bar{X})$ is unknown, then $\frac{\bar{X} - E(\bar{X})}{\widehat{\text{SD}}(\bar{X})} \sim t_{n-1}$.

--

So, when is $\bar{X} \sim N$? 

1. If the data are normal, i.e. $X_1, ..., X_n \sim N$.
    - check using histogram and/or QQ-plot

2. If $n \ge 30$, then CLT tells us $\bar{X} \sim N$ (in most real life scenarios...)

---

What if the data are not normal, and $n < 30$?!?!?!?!

.center[
![](./images/panic.gif)
]

---

What is the "gold standard" for finding the distribution of anything?

--

Sample from the population many, many times, and create a histogram. 

That's all fun and games in theory, but in practice we cannot really do that. 

Remember, all of statistics is build on one fundamental assumption: 
--
 the sample looks like the population.

So what if we just...
--
 resample from the sample...?

.center[
<img src="images/what.gif" width="300px" height="300px">
]

---

This approach is called *bootstraping*. How it works:

--

1. Grab your bootstraps

--

2. Pull yourself up!

.center[
<img src="images/bootstrap.gif" width="300px" height="300px">
]

---

This approach is called *bootstraping*. How it works:

--

1. Given a sample, calculate $\bar{x}$.

2. Generate a new sample of size $n$ from the original sample by sampling with replacement (!)
    * we call the first new sample $x_{11}, x_{12}, ..., x_{1n}$, the second new sample $x_{11}, x_{12}, ..., x_{1n}$, ..., the $B$'th new sample $x_{B1}, x_{B2}, ..., x_{Bn}$
    * these new samples are called *bootstrap samples*

3. For each bootstrap sample, calculate $t_j = \frac{\bar{x}_{\cdot j} - \bar{x}}{s_j/\sqrt{n}}$.
    * here, $\bar{x}_{\cdot j}$ is the average of the $j$'th bootstrap sample, while $\bar{x}$ is the average of the original sample. 

4. Estimate the distribution of $\frac{\bar{X} - E(\bar{X})}{\widehat{\text{SD}}(\bar{X})}$ by the distribution of $t_1, t_2, ..., t_B$
    * that is, the true distribution of $\frac{\bar{X} - E(\bar{X})}{\widehat{\text{SD}}(\bar{X})}$ is approximately the histogram of the $t_j$'s.

---
layout: true

# Confidence Intervals using Bootstrap

---

To find a confidence interval, we need to find $x_1, x_2$ such that 

$$
  P\left(x_1 \le \frac{\bar{X} - E(\bar{X})}{\widehat{\text{SD}}(\bar{X})} \le x_2 \right) = 1 - \alpha.
$$

We can use the bootstrap samples to estimate the distribution of $\frac{\bar{X} - E(\bar{X})}{\widehat{\text{SD}}(\bar{X})}$, and find the cut-offs such that there's $\alpha/2$ to the left of $x_1$ and $\alpha/2$ to the right of $x_2$. 

We will call $x_1 = \hat{t}_{1-\alpha/2}$, and $x_2 = \hat{t}_{\alpha/2}$ -- the $1-\alpha/2$ and $\alpha/2$ critical values of the distribution of the $\hat{t}_j$'s. 

Note: in this case, it is most likely that $\hat{t}_{1-\alpha/2} \neq -\hat{t}_{\alpha/2}$!!! There is no guarentee that the distribution is symmetrical, so no reason to think one of the values will be the negative of the other.

```{r echo = FALSE, eval = FALSE}
X <- Exponential(rate = 0.1)

sample_size <- 20

os <- tibble(x = random(X, n = sample_size))
```

---

Important: since we do not (a priori) know the distribution of the $\hat{t}_j$'s, we do not know if it is symmetrical. Therefore, we do not know if $\hat{t}_{1-\alpha/2} = -\hat{t}_{\alpha/2}$. So we do actually have to find **two** values.

This code takes an origina sample (`orig_sample`), creates 5000 bootstrap samples, and calculates $\hat{t}_1,...,\hat{t}_{5000}$. 

All of this will be in the data set `bootstrap_samples`.

```{r}
orig_sample <- tibble(x = c( 2.80, 16.47, 3.36,  9.31, 5.86, 
                            15.25, 27.58, 4.75, 36.20, 1.25, 
                            11.45, 10.01, 0.75,  0.59, 1.40, 
                            10.54, 20.69, 1.82, 10.16, 2.83))
xbar <- mean(orig_sample$x)
sample_size <- nrow(orig_sample)

bootstrap_samples <- tibble(i = 1:5000) %>% 
  mutate(boot_sample = map(i, ~sample_n(orig_sample, size = sample_size, replace = TRUE)$x),
         boot_mean = map_dbl(boot_sample, mean),
         boot_sd = map_dbl(boot_sample, sd),
         t_stat = (boot_mean - xbar)/(boot_sd/sqrt(sample_size)))
```

---

We can then create a histogram of the $\hat{t}_j$'s:

```{r}
ggplot(bootstrap_samples,
       aes(x = t_stat)) + 
  geom_histogram(binwidth = 0.1, 
                 aes(y = ..density..))
```

---

.pull-left[

<br/>
$\hat{t}_{1-\alpha/2}$ and $\hat{t}_{\alpha/2}$ are by definition the numbers that cut-off $1-\alpha/2$ and $\alpha/2$ of the area to the right, respectively. 
]
.pull-right[
```{r echo = FALSE}
ggplot(bootstrap_samples,
       aes(x = t_stat)) + 
  geom_histogram(binwidth = 0.1, 
                 aes(y = ..density..)) + 
  geom_vline(xintercept = quantile(bootstrap_samples$t_stat, p = c(0.025, 0.975)),
             color = "red", linetype = "dashed") + 
  scale_x_continuous("",
                     sec.axis = sec_axis(trans = "identity", 
                                         breaks = quantile(bootstrap_samples$t_stat, 
                                                           p = c(0.025, 0.975)),
                                         labels = c(expression(t[1-alpha/2]), 
                                                    expression(t[alpha/2]))))
```
]

In this case, the numbers are:

```{r t_qs, echo = TRUE, eval = TRUE}
bootstrap_samples %>% 
  summarize(t_left = quantile(t_stat, 0.025),
            t_right = quantile(t_stat, 0.975))
```

---

So, 

$$
\begin{aligned}
  1-\alpha &= P\left(\hat{t}_{1-\alpha/2} \le \frac{\bar{X} - E(\bar{X})}{\widehat{\text{SD}}(\bar{X})} \le \hat{t}_{\alpha/2}\right) \\
           &\\
           &= P\left(\hat{t}_{1-\alpha/2}\widehat{\text{SD}}(\bar{X}) \le \bar{X} - \mu \le \hat{t}_{\alpha/2}\widehat{\text{SD}}(\bar{X})\right) \\
           &\\
           &= P\left(-\bar{X}+\hat{t}_{1-\alpha/2}\widehat{\text{SD}}(\bar{X}) \le - \mu \le -\bar{X} + \hat{t}_{\alpha/2}\widehat{\text{SD}}(\bar{X})\right) \\
           &\\
           &= P\left(\bar{X}-\hat{t}_{1-\alpha/2}\widehat{\text{SD}}(\bar{X}) \ge \mu \ge \bar{X} - \hat{t}_{\alpha/2}\widehat{\text{SD}}(\bar{X})\right) \\
           &\\
           &= P\left(\bar{X}-\hat{t}_{\alpha/2}\widehat{\text{SD}}(\bar{X}) \le \mu \le \bar{X} - \hat{t}_{1-\alpha/2}\widehat{\text{SD}}(\bar{X})\right)
\end{aligned}
$$

---

A $(1-\alpha)\cdot 100\%$ Confidence Interval for the true mean $\mu$ is $[\bar{X}-\hat{t}_{\alpha/2}\widehat{\text{SD}}(\bar{X}), \bar{X} - \hat{t}_{1-\alpha/2}\widehat{\text{SD}}(\bar{X})]$. 

We are $(1-\alpha)\cdot 100\%$ confident that the true value is in this interval.

---
layout: true

# Confidence Intervals: Chick Birth Weights

---

The `ChickWeight` data have data regarding the effect of diet on early growth of chicks. 

```{r echo = FALSE}
ChickWeight <- as_tibble(ChickWeight)
```


```{r}
ChickWeight
```

We are interested in the mean birth weight of the chicks. This would not be affected by the diet, so treat as one big sample.

---

Want to find a confidence interval for $\mu$ = true mean birth weight.

```{r}
birth_weights <- ChickWeight %>% filter(Time == 0)

ggplot(birth_weights,
       aes(x = weight)) + 
  geom_histogram(binwidth = 1)
```

---

```{r}
ggplot(birth_weights,
       aes(sample = weight)) + 
  geom_qq() + 
  geom_qq_line()
```

Definitely not normal. 

---

BUT... $n = 50$! So, by CLT $\bar{X} \sim N$. Therefore, can construct a CI. Since we do not know true $\sigma$, find a $90\%$ CI as $\bar{x} \pm t_{n-1, 0.05} \frac{s}{\sqrt{n}}$.

What is $t_{n-1,0.05}$? The value on x-axis such that we cut-off $0.05$ to the right.

```{r echo = FALSE, fig.width = 6, out.width = "600px"}
T_49 <- StudentsT(df = nrow(birth_weights) - 1)
plot_pdf(T_49) +
  geom_auc(from = quantile(T_49, 0.95)) + 
  geom_vline(xintercept = quantile(T_49, 0.95), 
             color = "red", linetype = "dashed") + 
  annotate(x = 2.5, y = 0.1, geom = "text", label = "Shaded area is 0.05",
           hjust = 0.4, vjust = 0)
```

---

In R: remember that `quanile` finds the cut-off that cuts off to the left. To cut off 0.05 to the right, we cut off 0.95 to the left:

```{r echo = T}
T_49 <- StudentsT(df = 49) # n-1

(t_crit <- quantile(T_49, 0.95))
```

So, $90\%$ CI is

```{r echo = T}
birth_weights %>% 
  summarize(mean = mean(weight),
            sd = sd(weight),
            LL = mean - t_crit * sd/sqrt(50),
            UL = mean + t_crit * sd/sqrt(50))
```


---
layout: true

# Confidence Intervals: Biochemical Oxyden Demand

---

Measuring water quality over time. Done by measuring biochemical oxygen demand. 

Data:

```{r echo = T}
BOD
```

$n$ small, so cannot use CLT to conclude that $\bar{X} \sim N$. However, if the data is normal, we can still get to that same conclusion! 

---

QQ-plot:

```{r echo = T}
ggplot(BOD, aes(sample = demand)) + 
  geom_qq() + 
  geom_qq_line()
```

---

Is it straight enough? Not sure. Compare to other samples of same size that are *actually* from a normal with same mean and SD as our sample. Then ask: does our sample seem that much different?

```{r echo = T}
X <- Normal(mu = mean(BOD$demand), sigma = sd(BOD$demand))

normal_samples <- tibble(i = 1:9) %>% 
  mutate(data = map(i, ~random(X, n = nrow(BOD)))) %>% 
  unnest_longer(data)
```

.pull-left[
.small[
```{r more_qqs, echo = T, eval = F}
ggplot(normal_samples,
       aes(sample = data)) + 
  geom_qq() + 
  geom_qq_line() + 
  facet_wrap(~i)
```
]
]

.pull-right[
```{r ref.label="more_qqs", echo = FALSE}
```
]

---

I would probably say no. 


So, we assume $X_1, ..., X_6 \sim N$. We do not know $\sigma$, so find $99\%$ CI as $\bar{x} \pm t_{n-1,0.005} \frac{s}{\sqrt{n}}$. 

```{r echo = T}
T_5 <- StudentsT(df = 5) # n-1

(t_crit <- quantile(T_5, 0.995))
```

So, $99\%$ CI is

```{r echo = T}
BOD %>% 
  summarize(mean = mean(demand),
            sd = sd(demand),
            LL = mean - t_crit * sd/sqrt(50),
            UL = mean + t_crit * sd/sqrt(50))
```

---
layout: true

# Confidence Intervals: Effect of Drug on Sleep

---

Scientists are interested in the effect of soporific drugs on amount of sleep. Data actually has data for 10 patients in 2 groups, but we will only consider one of the groups. 

```{r}
sleep1 <- sleep %>% filter(group == 1)
sleep1
```


Small $n$, so no CLT. Is it normal?

---

QQ-plot:

```{r echo = T}
ggplot(sleep1, 
       aes(sample = extra)) + 
  geom_qq() + 
  geom_qq_line()
```

---

Is it straight enough? Not sure. Compare to other samples of same size that are *actually* from a normal with same mean and SD as our sample. Then ask: does our sample seem that much different?

```{r echo = T}
X <- Normal(mu = mean(sleep1$extra), sigma = sd(sleep1$extra))

normal_samples <- tibble(i = 1:9) %>% 
  mutate(data = map(i, ~random(X, n = nrow(sleep1)))) %>% 
  unnest_longer(data)
```

.pull-left[
.small[
```{r more_qqs2, echo = T, eval = F}
ggplot(normal_samples,
       aes(sample = data)) + 
  geom_qq() + 
  geom_qq_line() + 
  facet_wrap(~i)
```
]
]

.pull-right[
```{r ref.label="more_qqs2", echo = FALSE}
```
]

---

Not sure. After consulting with the scientists in charge of the study, it is decided that we do **NOT** want to assume normality. 

So, non-normal data, and $n$ too small for CLT. So, we opt for a bootstrap approach:

```{r echo = TRUE}
xbar <- mean(sleep1$extra)

bootstrap_samples <- tibble(i = 1:5000) %>% 
  mutate(boot_samples = map(i, ~sample_n(sleep1, size = 10, replace = TRUE)$extra),
         boot_mean = map_dbl(boot_samples, mean),
         boot_sd = map_dbl(boot_samples, sd),
         t_stat = (boot_mean - xbar)/(boot_sd/sqrt(10)))
```

---

Distribution from bootstrap:

```{r echo = TRUE}
ggplot(data = bootstrap_samples,
       aes(x = t_stat)) + 
  geom_histogram(bins = 100)
```

---

Want to create a $95\%$ CI for the true mean. Find $\hat{t}_{0.025}$ and $\hat{t}_{0.975}$:

```{r sleep-boot1, echo = TRUE, eval = T}
ggplot(data = bootstrap_samples,
       aes(x = t_stat)) + 
  geom_histogram(bins = 100) + 
  geom_vline(xintercept = quantile(bootstrap_samples$t_stat, 
                                   p = c(0.025, 0.975)),
             color = "red", linetype = "dashed")
```

---

We find these, estimated mean ( $\bar{x}$ ), and standard deviation ( $s$ ) in R

```{r}
bootstrap_samples %>% 
  summarize(t_left = quantile(t_stat, 0.025),
            t_right = quantile(t_stat, 0.975))
```


```{r}
sleep1 %>% 
  summarize(mean = mean(extra),
            sd = sd(extra),
            n = n())
```


---

```{r echo = FALSE}
CI <- sort(mean(sleep1$extra) - quantile(bootstrap_samples$t_stat, c(0.025, 0.975))*sd(sleep1$extra)/sqrt(nrow(sleep1)))
```


So, we find the lower limit of $95\%$ CI as 

$$
\begin{aligned}
\bar{x} - \hat{t}_{0.975} \frac{s}{\sqrt{n}} &= 0.75 - `r round(quantile(bootstrap_samples[['t_stat']], 0.975), digits = 3)`\frac{1.789}{\sqrt{10}}\\
&= `r round(CI[1], digits = 2)`
\end{aligned}
$$

and the upper limit as

So, we find the lower limit of $95\%$ CI as 

$$
\begin{aligned}
\bar{x} - \hat{t}_{0.025} \frac{s}{\sqrt{n}} &= 0.75 - (`r round(quantile(bootstrap_samples[['t_stat']], 0.025), digits = 3)`)\frac{1.789}{\sqrt{10}}\\
&= `r round(CI[2], digits = 2)`
\end{aligned}
$$