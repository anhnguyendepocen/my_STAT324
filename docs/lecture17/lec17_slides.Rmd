---
title: "Lecture 17: Two Sample Bootstrap, Wilcoxon Rank Sum Test"
subtitle: "STAT 324"
author: "Ralph Trane"
institute: "University of Wisconsin--Madison<br><br>"
date: "Spring 2020"
output:
  xaringan::moon_reader:
    css: [../css/uwmadison.css, default-fonts, ../css/extra-classes.css]
    lib_dir: libs
    nature:
      titleSlideClass: [center, top, .title-slide]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:10'
      navigation:
        scroll: false
---
layout: true

# Two Sample Bootstrap

---

```{r include = FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE,
                      dpi = 300, fig.height = 4, out.height = "400px",
                      fig.align = "center")

library(tidyverse)
theme_set(theme_bw())
```

When sage crickets *Cyphoderris strepitans* mate, the male allows the female to eat part of his hind wings. It was thought that the hunger level of a female may influence desire to mate. An experiment was conducted where 24 females were randomly assigned to two groups. One group of 11 was starved for two days, and the other group of 13 was fed normally. Each female was presented with a male and the time to mating (in hours) was recorded. The primary research question was, ”Do starved females attempt mating more or less quickly than normally fed females?”

--

The primary research question was, "Do starved females attempt mating more or less quickly than normally fed females?"

--

The hypotheses are as follows:

$$H_0: \mu_\text{starved} - \mu_\text{fed} = 0 \quad vs. \quad H_A: \mu_\text{starved} - \mu_\text{fed} \neq 0.$$

We will use $\alpha = 0.05$.

---

Data:

```{r}
crickets <- tibble(hours = c(1.9, 2.1, 3.8, 9.0, 9.6, 13.0, 14.7, 17.9, 21.7, 29.0, 72.3,
                             1.5, 1.7, 2.4, 3.6, 5.7, 22.6, 22.8, 39.0, 54.4, 72.1, 73.6, 79.5, 88.9),
                   group = rep(c("starved", "fed"), c(11, 13)))

DT::datatable(crickets, 
              options = list(pageLength = 7, dom = "tip"))
```

---

Summaries:

.pull-left[
```{r crickets_summaries, eval = FALSE}
crickets %>% 
  group_by(group) %>% 
  summarize(Mean = mean(hours),
            s = sd(hours),
            n = n())
```
]

.pull-right[
```{r ref.label="crickets_summaries", echo = FALSE}
```
]


--

At this point, one might consider a two-sample t-test. You could argue both for and against assuming equal variances. Personally, I would not. 

To actually perform a two-sample t-test, we need the following assumptions to hold:

--

1. Independent groups

2. Independent samples

3. Normal averages

---

Boxplots:

```{r}
ggplot(crickets, aes(x = group, y = hours)) +
  geom_boxplot() +
  geom_jitter(width = 0.2, aes(color = group)) 
```

---

Histograms:

```{r}
ggplot(crickets, 
       aes(x = hours)) +
  geom_histogram(bins = 10) + 
  facet_grid(group ~ .)
```


---

Observations: 

--

* sample sizes both less than 30, and data do not look normal (skewed)

--

* variances may or may not be equal

--

* potential outlier in starved group

--

Two sample t-test still reasonable? 
--
No. Non normal averages. 

--

What to do instead? 
--
One option is a two-sample bootstrap test. 


---

```{r}
crickets %>% 
  group_by(group) %>% 
  summarize(ave = mean(hours),
            s = sd(hours),
            n = n()) %>% print %>% 
  summarize(diff_ave = ave[2] - ave[1],
            sd_ave = sqrt(sum(s^2/n)),
            t_obs = diff_ave/sd_ave)
```


---

```{r cache = TRUE}
starved_crickets <- crickets %>% 
  filter(group == "starved")

fed_crickets <- crickets %>% 
  filter(group == "fed")


bootstrap_samples <- tibble(i = 1:5000) %>% 
  mutate(bootstrap_fed = map(i, ~sample_n(fed_crickets, 
                                          size = 13, replace = TRUE)$hours),
         bootstrap_starved = map(i, ~sample_n(starved_crickets, 
                                              size = 11, replace = TRUE)$hours),
         boot_mean_fed = map_dbl(bootstrap_fed, mean),
         boot_mean_starved = map_dbl(bootstrap_starved, mean),
         boot_sd_fed = map_dbl(bootstrap_fed, sd),
         boot_sd_starved = map_dbl(bootstrap_starved, sd),
         boot_t = (boot_mean_starved - boot_mean_fed - (-18.25734))/
           (sqrt(boot_sd_starved^2/13 + boot_sd_fed^2/11)))
```

---

```{r}
ggplot(bootstrap_samples,
       aes(x = boot_t)) +
  geom_histogram(bins = 50) +
  geom_vline(xintercept = -1.64476, 
             linetype = "dashed", 
             color = "red")
```

---

p-value, and $95\%$ Confidence Interval for the difference in means:

```{r}
bootstrap_samples %>% 
  summarize(LL = -18.25734 - quantile(boot_t, 0.975)*11.10031,
            UL = -18.25734 - quantile(boot_t, 0.025)*11.10031,
            p_value = (sum(boot_t < -1.64476) + sum(boot_t > 1.64476))/5000)
```

We do not reject the null hypothesis - the data does not provide sufficient evidence to convince us that there is a difference in mean time to mating. 

---
layout: true

# Wilcoxon Rank Sum Test

---

Different approach: change the question from "difference in means" to "shift in location".

General example: 

```{r echo = F, cache = TRUE}
library(distributions3)

ggplot(data = tibble(x = seq(0, 20, by = 0.025),
                     y = pdf(ChiSquare(5), x))) +
  geom_area(aes(x = x, y = y),
            fill = "red", alpha = 0.5) + 
  geom_area(aes(x = x + 2, y = y),
            fill = "blue", alpha = 0.5) + 
  geom_area(aes(x = x + 4, y = y),
            fill = "yellow", alpha = 0.5) +
  coord_cartesian(xlim = c(0, 20))
```

---

If we compare red and yellow curves: 

* generally expect values from red curve to be smaller than values from yellow

--

* even more sure that 
    * smallest values from red < smallest values from yellow
    * middle values from red < middle values from yellow
    * largest values from red < largest values from yellow

--

What if there is no shift? Whether largest values from red are greater than largest values from yellow or not is basically a coin toss - could go either way.

--

So, if we rank all values (both those from red and yellow): 

* if there is a shift, values from red will generally have lower rank than values from yellow

* if there is no shift, the ranks will be randomly distributed between the two groups.

Will use this fact for a hypothesis test for location shift. More formally: 

$$H_0: \text{two populations follow same distribution} \\ \text{vs.} \\ H_A: \text{two populations follow distributions with same shape, but on is shifted}$$

---

.pull-left[
```{r crickets_ranked, eval = FALSE}
crickets_ranked <- crickets %>%
  mutate(rank = rank(hours))

DT::datatable(crickets_ranked,
              options = list(dom = "t",
                             paging = FALSE,
                             scrollY = "50vh"))
```

```{r crickets_ranked_plot, eval = FALSE}
ggplot(crickets_ranked,
       aes(x = rank, y = group)) +
  geom_point() +
  scale_x_continuous(minor_breaks = 1:24)
```

If the distribution of the observations from the starved group is shifted right compared to the distribution of the observations from the fed group, the ranks in the starved group would generally be large. I.e. the *sum of the ranks* in the starved group would be large. 

]

.pull-right[
```{r ref.label="crickets_ranked", echo = FALSE} 
```

```{r ref.label="crickets_ranked_plot", echo = FALSE, fig.width = 4, fig.height = 2, out.width = "500px", out.height = "250px"}
```
]

---

So, we somehow have to find out if the sum of the ranks in the starved group is large. 

A natural thing to compare to is the *smallest* possible sum of ranks. The smallest possible sum would be if all observations in the starved group are smaller than all observations in the fed group. If this is the case, the ranks of observations in the starved group would be $1,2,3,...,11$. So, the sum would be $1 + 2 + ... + 11 = 66$.

Our *test statistic* is the difference between the observed sum of ranks, and the smallest possible sum of ranks: $U = R - R_\text{min}$.

```{r}
crickets_ranked %>% 
  filter(group == "starved") %>% 
  summarize(R_obs = sum(rank),
            R_min = sum(1:n()),
            U_obs = R_obs - R_min)
```

---

The next question we would like to answer: "is $U_\text{obs}$ unexpectedly large or small, if the null hypothesis is true?" To answer this question, we need the distribution of $U$ so that we can find the p-value. This is where things become very tricky... 

To illustrate how this is done, we will consider a much simpler scenario: 


.pull-left[
```{r}
simple_example <- tibble(group = rep(c("A", "B"), c(2, 3)),
                         observations = c(4.8, 2.2, 3.0, 1.5, 3.5)) %>% 
  mutate(rank = rank(observations))

simple_example
```
]

.pull-right[
For the Wilcoxon Rank Sum Test, we only focus on one of the groups. Let's pick group A. 

The observed rank sum for group A: $R_\text{obs} = 2 + 5 = 7$.

Smallest possible rank sum for group A: $R_\text{min} = 1 + 2 = 3$. 

Observed value of the test statistic: $U_\text{obs} = 7 - 3 = 4$. 
]

---

If the null hypothesis $H_0:$ the two groups follow identical distributions is true, then the ranks in group A might as well have been $3$ and $4$. Or $1$ and $6$. In fact, if $H_0$ is true, any possible ranking is equally likely. 

How many different rankings can we get, when we are only interested in group A? ${5 \choose 2} = 10$ (choose 2 locations out of 5 possibilities.)

When the sample size is small enough, as is the case here, we can write out all possible combinations, and for each of them calculate the value of the test statistic.

This will allow us to get the pmf of the test statistic, which we then can use to find the p-value!

```{r echo = FALSE}
Us <- expand_grid(obs1 = 1:5, 
            obs2 = 2:5) %>% 
  filter(obs2 > obs1) %>% 
  mutate(R = obs1 + obs2,
         R_min = 1+2,
         U = R - R_min,
         `P(U)` = 1/n()) %>% 
  rename(`Rank of obs 1` = obs1,
         `Rank of obs 2` = obs2,
         R_min = R_min)
```

---

.pull-right[
```{r echo = FALSE}
Us %>% 
  knitr::kable(format = "html") %>% 
  kableExtra::kable_styling()
```
]

---

.pull-left[

If our alternative hypothesis is $H_A:$ "group A is shifted to the left of B", then

$$\text{p-value} = P(U \le U_\text{obs}) = \frac{8}{10} = 0.8$$

]

.pull-right[
```{r echo = FALSE}
Us %>% 
  knitr::kable(format = "html") %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::row_spec(row = which(Us$U <= 4), background = "grey", color = "white")
```
]


---

.pull-left[

If our alternative hypothesis is $H_A:$ "group A is shifted to the left of B", then

$$\text{p-value} = P(U \le U_\text{obs}) = \frac{8}{10} = 0.8$$

If our alternative hypothesis is $H_A:$ "group A is shifted to the right of B", then

$$\text{p-value} = P(U \ge U_\text{obs}) = \frac{4}{10} = 0.4$$


]

.pull-right[
```{r echo = FALSE}
Us %>% 
  knitr::kable(format = "html") %>% 
  kableExtra::kable_styling() %>% 
  kableExtra::row_spec(row = which(Us$U >= 4), background = "grey", color = "white")
```
]

---


.pull-left[

If our alternative hypothesis is $H_A:$ "group A is shifted to the left of B", then

$$\text{p-value} = P(U \le U_\text{obs}) = \frac{8}{10} = 0.8$$

If our alternative hypothesis is $H_A:$ "group A is shifted to the right of B", then

$$\text{p-value} = P(U \ge U_\text{obs}) = \frac{4}{10} = 0.4$$

If our alternative hypothesis is $H_A:$ "group A is shifted from B", then

$$\begin{aligned}
\text{p-value} &= 2\cdot \min\left\{ P(U \le U_\text{obs}), P(U \ge U_\text{obs}\right\} \\ 
               &= 2\cdot\frac{4}{10} = 0.8
\end{aligned}$$

]

.pull-right[
```{r echo = FALSE}
Us %>% 
  knitr::kable(format = "html") %>% 
  kableExtra::kable_styling()
```
]

---

Returning to the crickets: we have 24 crickets in total, and 11 in the starved group. I.e. there's ${24 \choose 11} = `r format(choose(24,11), scientific = FALSE, big.mark = ",")`$ possible combinations... 

--

We're obviously not going to calculate all possible combinations of ranks, but rather rely on `R` to do so for us:

```{r}
crickets <- crickets %>% 
  mutate(group = factor(group, 
                        levels = c("starved", "fed")))

wilcox.test(data = crickets,
            hours ~ group)
```

Notice how $W = U_\text{obs}$. 

---

Quick note: if we change the group we focus on, we get same p-value when the alternative is two-sided:

```{r}
crickets <- crickets %>% 
  mutate(group = factor(group, 
                        levels = c("fed", "starved")))

wilcox.test(data = crickets,
            hours ~ group)
```

For one-sided, the p-vales are switched:

---

```{r}
crickets <- crickets %>% 
  mutate(group = factor(group, 
                        levels = c("fed", "starved")))

wilcox.test(data = crickets,
            hours ~ group, alternative = "less")
wilcox.test(data = crickets,
            hours ~ group, alternative = "greater")
```

---

```{r}
crickets <- crickets %>% 
  mutate(group = factor(group, 
                        levels = c("starved", "fed")))

wilcox.test(data = crickets,
            hours ~ group, alternative = "less")
wilcox.test(data = crickets,
            hours ~ group, alternative = "greater")
```


---

Assumptions made:

* independent groups

* independent samples

* shapes of the two groups approximately the same

    - hard to check!!

---
layout: true

# Pros/Cons

---

Before discussing pros and cons, let's just for good measure see what would have happened had we used a two sample t-test:

```{r}
t.test(data = crickets, hours ~ group, var.equal = FALSE)
```

I chose to NOT assume equal variances:

* if variances are in fact equal, but not assumed equal, some power is lost

* if variances are NOT equal, but assumed equal, test might lead to crazy conclusions.

Therefore, when in doubt, don't assume equal variance. Here, ratios of SDs border line (`r crickets %>% group_by(group) %>% summarize(s = sd(hours)) %>% summarize(ratio = s[2]/s[1]) %>% pull(ratio) %>% round(digits = 3)`), so the safe choice is to NOT assume equal variances.

---
 
T-test:

* Need normality of averages
* If normal averages, more powerful
* Dealing with means, so impacted by outliers

Bootstrap:

* No need for normality
* Still means, still impacted by outliers

Wilcoxon:

* No need for normality
* Assumes similar shapes, which is hard to check
* Dealing with ranks, so more *robust* towards outliers
    * changing extreme values doesn't change ranks

---

```{r}
original <- crickets %>% 
  summarize(Analysis = "Original",
            t_test_p_value = t.test(hours ~ group)$p.value,
            t_test_LL = t.test(hours ~ group)$conf.int[1],
            t_test_UL = t.test(hours ~ group)$conf.int[2],
            wilcox_p_value = wilcox.test(hours ~ group)$p.value)

remove_outliers <- crickets %>% 
  group_by(group) %>% 
  filter(hours < quantile(hours, 0.75) + IQR(hours) * 1.5,
         hours > quantile(hours, 0.25) - IQR(hours) * 1.5) %>% 
  ungroup() %>% 
  summarize(Analysis = "Remove Outliers", 
            t_test_p_value = t.test(hours ~ group)$p.value,
            t_test_LL = t.test(hours ~ group)$conf.int[1],
            t_test_UL = t.test(hours ~ group)$conf.int[2],
            wilcox_p_value = wilcox.test(hours ~ group)$p.value)

change_max <- crickets %>% 
  mutate(hours = if_else(hours == max(hours), 10000, hours)) %>% 
  summarize(Analysis = "Change Max",
            t_test_p_value = t.test(hours ~ group)$p.value,
            t_test_LL = t.test(hours ~ group)$conf.int[1],
            t_test_UL = t.test(hours ~ group)$conf.int[2],
            wilcox_p_value = wilcox.test(hours ~ group)$p.value)
```

---


```{r}
bind_rows(original, remove_outliers, change_max) %>% 
  knitr::kable(format = "html")
```
