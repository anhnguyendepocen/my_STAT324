---
title: "Lecture 11: CI Wrap-up, & Intro to Hypothesis Testing"
subtitle: "STAT 324"
author: "Ralph Trane"
institute: "University of Wisconsin--Madison<br><br>"
date: "Spring 2020"
output:
  xaringan::moon_reader:
    self_contained: true
    css: [../css/uwmadison.css, default-fonts, ../css/extra-classes.css]
    lib_dir: libs
    nature:
      titleSlideClass: [center, top, .title-slide]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ration: '16:9'
      navigation:
        scroll: false
---

# Practicalities

* Midterm I on Tuesday 3/3 in class (4.00p-5.15p in Van Vleck B130)

    * Notes are allowed
    
    * Calculator recommended
    
    * No connected devices!
    
    * Practice problem set on Canvas
    
    * Q/A Review tomorrow and Thursday
    
    * No homework assigned this week

---

# Misc.

* Recap of $t$-distribution/introduction of t-table

* Comment on homework questions re: sample size.


---

# Recap of Confidence Intervals

1. Want to do better than just a single "best guess" (= point estimate)

2. Find a good estimator for parameter of interest 
    * think $\bar{X}$ for $\mu$, or $P$ for $\pi$

3. Find distribution of some quantity involving estimator and parameter of interest
    * $\frac{\bar{X} - \mu}{s/\sqrt{n}} = \frac{\bar{X} - E(\bar{X})}{\widehat{\text{SD}}(\bar{X})}$

4. Find critical values in the distribution
    * i.e. cut-off $\alpha/2$ on each side of distribution

5. Rearrange $P\left(x_1 < \text{ quantity from 3 } < x_2\right)$ until parameter of interest is in the middle
    * for example, $P\left(-z_{\alpha/2} < \frac{\bar{X} - \mu}{s/\sqrt{n}} < z_{\alpha/2}\right)$ becomes $P(\bar{X} - t_{n-1,\alpha/2}\tfrac{s}{\sqrt{n}} < \mu < \bar{X} + t_{n-1, \alpha}\tfrac{s}{\sqrt{n}})$.

---

# Recap of Confidence Intervals

The hard part: how do we find the distribution of quantity? 

Often, how do we find the distribution of $\frac{\bar{X} - E(\bar{X})}{\widehat{\text{SD}}(\bar{X})}$? 

A few tricks:

1. If $\bar{X} \sim N$, then $\frac{\bar{X} - E(\bar{X})}{\widehat{\text{SD}}(\bar{X})} \sim t_{n-1}$.

2. If $\bar{X}$ not necessarily normal, then bootstrap.

Two things result in $\bar{X} \sim N$:

1. Data themselves are normal
    - i.e. $X_1,...,X_n \sim N$

2. $n > 30$, because then CLT

---

# Recap of Confidence Intervals

Once we get an interval, how do we interpret it?

* The standard phrase: "We are $(1-\alpha)\cdot 100\%$ confident the interval contains the true value"

* Confident = repeating the process many times will cover the truth $(1-\alpha)\cdot 100\%$ of the time

* The CI is a range of values we find plausible to be the truth given the data (at a certain level of confidence)

---
layout: true

# Introduction to Statistical Hypothesis Testing

---

Sometimes we have that one thing we are really interested in: "does it seem likely that the true mean is 5?"

--

First step in answering this question: write down your *statistical hypotheses*. These always come in pairs:

* the *null* hypothesis is the simplest (and often uninteresting) hypothesis
    * we take this to be "status quo" - we are trying to dismiss this
    
* the *alternative* hypothesis is what we will test against
    * this is what we will adopt, if we dismiss "status quo"

--
 
Example: "is the true mean 5?" would dictate the null hypothesis $H_0: \mu = 5$. We now have a choice for the alternative:

* $H_A: \mu > 5$
* $H_A: \mu < 5$
* $H_A: \mu \neq 5$

For now, focus on the first one. 

---

```{r echo = FALSE, warning = FALSE, message = FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      dpi = 300, fig.width = 4, fig.height = 3, fig.align = "center")

library(tidyverse)
library(distributions3)

set.seed(150906)

theme_set(theme_minimal())

X <- Normal(mu = 6, sigma = 2)

X2 <- Normal(mu = 6, sigma = 4)

sample_size <- 20

samp0 <- tibble(x = random(X, n = sample_size),
               x2 = random(X2, n = sample_size)) %>% 
  mutate(x2 = x2 - (mean(x2) - mean(x)))

samp <- samp0 %>% select(x)

xbar <- round(mean(samp$x), digits = 3)
```


Want to test $H_0: \mu = 5$ vs. $H_A: \mu > 5$. 

Gather data, estimate $\mu$. 

```{r echo = TRUE}
head(samp,n = 5)
```

```{r}
samp <- samp0
```


We get $\bar{x}_{\text{obs}} = `r xbar`$. 

--
 
Conclusion: since $\bar{x}_{\text{obs}} > 5$, surely $\mu > 5$?

--

Of course not! We never expect $\bar{X}$ to be **exactly** the true mean, simply "close to it". 

Remember, $H_0: \mu = 5$ is status quo. So the question is, is $\bar{x}_{\text{obs}}$ far enough from $5$ that we no longer think $\mu = 5$?

---
layout: true

# Introduction to Statistical Hypothesis Testing

**Question**: is $\bar{x}_{\text{obs}}$ far enough from $5$ that we throw away $H_0$? 

---

```{r}
ggplot(samp, aes(x = x)) + 
  geom_vline(data = data.frame(xint = c(5, xbar), 
                               col = c("H0", "xbar")), 
             aes(xintercept = xint, color = col),
             linetype = "dashed") +
  scale_x_continuous("", breaks = c(5, xbar)) +
  scale_color_discrete("", labels = c(expression(H[0]), expression(bar(x)))) +
  theme(panel.grid = element_blank(),
        legend.position = "top")
```


---

```{r}
ggplot(samp, aes(x = x, y = 1)) + 
  geom_vline(data = data.frame(xint = c(5, xbar), 
                               col = c("H0", "xbar")), 
             aes(xintercept = xint, color = col),
             linetype = "dashed") +
  geom_jitter(width = 0, height = 0.1) +
  scale_x_continuous("") +
  scale_y_continuous("", limits = c(0.5, 1.5)) + 
  scale_color_discrete("", labels = c(expression(H[0]), expression(bar(x)))) +
  theme(panel.grid = element_blank(),
        legend.position = "top",
        axis.text.y = element_blank())
```

---

```{r}
ggplot(samp, aes(x = x2, y = 1)) + 
  geom_vline(data = data.frame(xint = c(5, xbar), 
                               col = c("H0", "xbar")), 
             aes(xintercept = xint, color = col),
             linetype = "dashed") +
  geom_jitter(width = 0, height = 0.1) +
  scale_x_continuous("") +
  scale_y_continuous("", limits = c(0.5, 1.5)) + 
  scale_color_discrete("", labels = c(expression(H[0]), expression(bar(x)))) +
  theme(panel.grid = element_blank(),
        legend.position = "top",
        axis.text.y = element_blank())
```

---

Where do we draw the line? 

```{r fig.height = 5, fig.width = 7.5, out.height = "500px", out.width = "750px"}
sigmas <- 1:6

many_samples <- tibble(i = 1:6) %>% 
  mutate(x = map(i, ~random(Normal(mu = X$mu, sigma = sigmas[.x]), 
                            n = sample_size)),
         x = map(x, ~.x - (mean(.x) - mean(samp$x)))) %>% 
  unnest_longer(col = x) %>% 
  # bind_rows(
  #   samp %>% 
  #     gather(key = 'i', value = "value") %>% 
  #     mutate(i = if_else(i == "x", 4, 6)) %>% 
  #     rename(x = value)
  # ) %>% 
  arrange(i)

pos_jit <- position_jitter(width = 0, height = 0.1)

ggplot(data = many_samples,
       aes(x = x, y = 1)) + 
  geom_vline(data = data.frame(xint = c(5, xbar), 
                               col = c("H0", "xbar")), 
             aes(xintercept = xint, color = col),
             linetype = "dashed") +
  geom_point(position = pos_jit) +
  scale_x_continuous("") +
  scale_y_continuous("", limits = c(0.75, 1.25), breaks = NULL) + 
  scale_color_discrete("", labels = c(expression(H[0]), expression(bar(x)))) +
  facet_wrap(~i, nrow = 3) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        legend.position = "top",
        axis.text.y = element_blank())
```

---

Where do we draw the line? Kind of comparing difference to variation.

```{r fig.height = 5, fig.width = 7.5, out.height = "500px", out.width = "750px"}
ggplot(data = many_samples,
       aes(x = x, y = 1)) + 
  geom_vline(data = data.frame(xint = c(5, xbar), 
                               col = c("H0", "xbar")), 
             aes(xintercept = xint, color = col),
             linetype = "dashed") +
  geom_point(position = pos_jit) +
  scale_x_continuous("") +
  scale_y_continuous("", limits = c(0.75, 1.25), breaks = NULL) + 
  scale_color_discrete("", labels = c(expression(H[0]), expression(bar(x)))) +
  facet_wrap(~i, nrow = 3) +
  # geom_text(data = many_samples %>% 
  #             group_by(i) %>% 
  #             summarize(t = format(round((mean(x) - 5)/(sd(x)/sqrt(n())), 
  #                                        digits = 3),
  #                                  nsmall = 3)),
  #           x = Inf, y = Inf, hjust = 1.3, vjust = 1.5,
  #           aes(label = t)) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        legend.position = "top",
        axis.text.y = element_blank())
```

---
layout: true

# Introduction to Statistical Hypothesis Testing

---

Comparing $\bar{X} - \mu$ to a measure of variation. Which of the following provide most evidence against the null $H_0: \mu = 5$?

```{r fig.height = 4.5, fig.width = 7.5, out.height = "450px", out.width = "750px"}
sig <- 1

many_samples2 <- tibble(i = 1:6) %>% 
  mutate(x = map(i, ~random(Normal(mu = X$mu, sigma = sig), 
                            n = 5*.x)),
         x = map(x, ~.x/sd(.x)*sig),
         x = map(x, ~.x - (mean(.x) - mean(samp$x)))) %>% 
  unnest_longer(col = x) %>% 
  arrange(i)

ggplot(data = many_samples2,
       aes(x = x, y = 1)) + 
  geom_vline(data = data.frame(xint = c(5, xbar), 
                               col = c("H0", "xbar")), 
             aes(xintercept = xint, color = col),
             linetype = "dashed") +
  geom_point(position = pos_jit) +
  scale_x_continuous("") +
  scale_y_continuous("", limits = c(0.75, 1.25), breaks = NULL) + 
  scale_color_discrete("", labels = c(expression(H[0]), expression(bar(x)))) +
  facet_wrap(~i, nrow = 3) +
  geom_text(data = many_samples2 %>% 
              group_by(i) %>% 
              summarize(t = format(round(sd(x), digits = 2),
                                   nsmall = 2)),
            x = Inf, y = Inf, hjust = 1.3, vjust = 1.5,
            aes(label = t)) +
  theme_bw() +
  theme(panel.grid = element_blank(),
        legend.position = "top",
        axis.text.y = element_blank())
```

--

Would like our measure to have some dependency on $n$. 

---

What if we use $\frac{\bar{X} - \mu}{\widehat{\text{SD}}(\bar{X})}$? 

* measures deviation from hypothesized mean relative to measure of variation

* if difference $\bar{X} - \mu$ is large, this quantity is large

* since $\widehat{\text{SD}}(\bar{X}) = s/\sqrt{n}$, larger $n$ implies larger value

Intuitively, smart choice!

--

But when is this "large enough" that we would throw out $H_0: \mu = 5$?

---

Let's pretend that $\mu=5$. I.e. pretend $E(X_i) = 5$. Then $E(\bar{X}) =$
--
 $5$. 

Let's pretend $\bar{X} \sim N$. (Does this seem outrageous?
--
 No, because CLT!)

So, $T = \frac{\bar{X} - 5}{\widehat{\text{SD}}(\bar{X})} \sim t_{n-1}$. 

This is great! We can now say something about " is the observed $\bar{x}_{\text{obs}}$ far from $5$?", **IF** $H_0: \mu = 5$ is true! 

If $\bar{x}_{\text{obs}}$ is close to $5$, then $T_{\text{obs}}$ is close to $0$. (Here $T_{\text{obs}}$ is the observed value of $T$.)

**IF** $H_0: \mu = 5$, we can find $P\left(T > T_{\text{obs}}\right)$.

In other words, **IF** $H_0: \mu = 5$, we can find *the probability of seeing something "more absurd"/"more extreme"/"further away"* than what we observe.

If this probability is small, our $\bar{x}_{\text{obs}}$ is deemed "far from" the hypothesized mean of $5$, hence the sample seems to suggest that $\mu = 5$ is not the correct value. 

---

So, we have taken the question "is `r xbar` far from $5$?", which is highly subjective, and reformulated it as "is the probability of observing something "more extreme" large?", which is...
--
 still highly subjective, **BUT** now on a scale we all know and love!

--

This new question is unitless - it is a probability between 0 and 1. 

You might think $0.1$ is small, while I would use $0.01$ as a cut-off for "small", but at least we are now operating on the same scale AND we can relate to the choice of others.

---

```{r}
t_obs <- (xbar-5)/(sd(samp$x)/sqrt(nrow(samp)))
```


So, is `r xbar` far from $5$? Find $T_{\text{obs}} = \frac{\bar{x}_{\text{obs}} - 5}{s/\sqrt{`r sample_size`}} = `r round(t_obs, digits = 3)`$ and see if it is far from $0$:

```{r fig.height = 2, fig.width = 4, out.height = "300px", out.width = "600px"}
ggplot() +
  geom_vline(data = data.frame(xint = c(0, t_obs), 
                               col = c("H0", "xbar")), 
             aes(xintercept = xint, color = col),
             linetype = "dashed") + 
  # geom_pdf(d = StudentsT(df = nrow(samp)-1),
  #          limits = c(-3.5, t_obs+0.1),
  #          aes(color = "T")) + 
  scale_color_manual("", 
                     values = c("blue", "red"),
                     labels = c(expression(H[0]), 
                                #expression(t[29]),
                                bquote(frac(bar(x) - 5,s/sqrt(.(sample_size)))))) +
  labs(x = "", y = "") +
  theme_bw() +
  theme(panel.grid = element_blank(),
        #legend.position = "top",
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())
```

---

So, is `r xbar` far from $5$? Find $T_{\text{obs}} = \frac{\bar{x}_{\text{obs}} - 5}{s/\sqrt{`r sample_size`}} = `r round(t_obs, digits = 3)`$ and see if it is far from $0$, when compared to the $t_{n-1}$-distribution:

```{r fig.height = 2, fig.width = 4, out.height = "300px", out.width = "600px"}
ggplot() +
  geom_vline(data = data.frame(xint = c(0, t_obs), 
                               col = c("H0", "xbar")), 
             aes(xintercept = xint, color = col),
             linetype = "dashed") + 
  geom_pdf(d = StudentsT(df = nrow(samp)-1),
           limits = c(-3.5, t_obs+0.1),
           aes(color = "T")) +
  scale_color_manual("", 
                     values = c("blue", "black", "red"),
                     labels = c(expression(H[0]), 
                                bquote(t[.(sample_size - 1)]),
                                bquote(frac(bar(x) - 5,s/sqrt(.(sample_size)))))) +
  scale_y_continuous(expand = expand_scale(0, c(0, 0.1))) +
  labs(x = "", y = "") +
  theme_bw() +
  theme(panel.grid = element_blank(),
        #legend.position = "top",
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank())
```

---

The most general strategy:

1. Set up null and alternative hypotheses:
    - $H_0: \mu = \mu_0$ vs. 
        - $H_A: \mu > \mu_0$ or $H_A: \mu < \mu_0$ or $H_A: \mu \neq \mu_0$
2. Pick cut-off for "small probability"
    - called *significance level* and is denoted by $\alpha$
    - often $0.05$, $0.01$, or $0.001$
2. Find good good *test statistic*
    - example: when wondering about true mean, $T = \frac{\bar{X} - \mu_0}{s/\sqrt{n}}$
3. Find distribution *assuming $H_0$ is true!*
    - if $H_0: \mu = \mu_0$ is true, then $T \sim t_{n-1}$
4. Find the *p-value*: probability of being "more extreme"
    - if $H_A: \mu > \mu_0$, "more extreme" = even larger, so find $P(T > T_{\text{obs}})$
    - if $H_A: \mu < \mu_0$, "more extreme" = even smaller, so find $P(T < T_{\text{obs}})$
    - if $H_A: \mu \neq \mu_0$, "more extreme" = even further away from zero, so find $P(T > |T_{\text{obs}}|) + P(T < -|T_{\text{obs}}|)$

---

Performing a hypothesis test results in one of two thing: 

1. lots of evidence against the null (i.e. $\bar{x}_{\text{obs}}$ is far from $\mu$ above) leads us to *reject* $H_0$

2. less evidence against the null (i.e. $\bar{x}_{\text{obs}}$ is close to $\mu$ above) leads us to *not reject* $H_0$

Note: 

* we **NEVER** accept the null, we **NEVER** accept the alternative. 

* we **NEVER** find the truth, we simply reject suggestions.

---

We will never know the truth, so mistakes happen:

1. If we reject the null, but the null is actually true, we make a **type I** error.

2. If we do not reject the null, but the null is actually false, we make a **type II** error.

```{r}
expand_grid(Result = c("Reject", "Do not reject"),
            Truth = c("H<sub>0</sub> true", "H<sub>0</sub> false")) %>% 
  mutate(outcome = c("Type I", "No mistake", "No mistake", "Type II" )) %>% 
  spread(Truth, outcome) %>% 
  arrange(desc(Result)) %>% 
  rename("Result\\Truth" = Result) %>% 
  select(1,3,2) %>% 
  knitr::kable(format = "html", escape = FALSE) %>% 
  kableExtra::column_spec(column = 1, bold = TRUE)
```

Since we never know the truth, we cannot check if a mistake occurred, but we can control the probability it occurs.

We use 

$$P(\text{type I error}) = P(\text{reject } H_0 | H_0 \text{ true}) = \alpha$$ 

and 

$$P(\text{type II error}) = P(\text{do not reject } H_0 | H_0 \text{ false}) = \beta$$

---

Generally, we want $\alpha$ and $\beta$ to be
--
 small.


Closely related to $\beta$ is the idea of *statistical power*: the probability that we reject $H_0$ when $H_0$ is indeed false! I.e.

$$
\text{Power} = P(\text{reject } H_0 | H_0 \text{ false}) = 1 - P(\text{do not reject } H_0 | H_0 \text{ false}) = 1 - \beta.
$$

So, we want power to be
--
 large. 

Unfortunately, (for fixed sample size $n$) decreasing $\alpha$ increases $\beta$, and vice versa! So a trade-off to be made - do you want lower probability of Type I error, or lower probability of type II error. 


---

Three more concepts that are closely related: *significance level*, *p-value*, and *rejection region*.

* The *significance level* is your cut-off for what constitutes a small probability. 

* The *p-value* is the probability of observing something more extreme **IF** the null hypothesis is true
    - p-value $= P(\text{more extreme}|H_0 \text{ true})$.
    - what it means to be "more extreme" is determined by $H_A$

* The *rejection region* (RR) is all the values that would result in a p-value smaller than the significance level
    - the opposite of the rejection region is called the *acceptance region* 

---

Consider $H_0: \mu = 5$ vs. $H_A: \mu > 5$.

We might choose a significance level of $0.05$. I.e. we would reject if area to the right of the observed value of our test statistic is greater than $0.05$. 

```{r fig.height = 2, fig.width = 4, out.height = "300px", out.width = "600px"}
ggplot() + 
  geom_pdf(d = StudentsT(df = 29)) +
  geom_vline(aes(xintercept = t_obs, color = "xbar"), linetype = "dashed") +
  scale_x_continuous("", breaks = c(0, t_obs), 
                     labels = c(0, round(t_obs, digits=3))) +
  scale_y_continuous("", expand = expand_scale(0, c(0,0.1))) +
  scale_color_manual("", values = c("red"), labels = expression(T[obs])) +
  theme(panel.grid = element_blank(),
        axis.text.y = element_blank(),
        axis.line.x = element_line())
```


---

Consider $H_0: \mu = 5$ vs. $H_A: \mu > 5$.

We might choose a significance level of $0.05$. I.e. we would reject if area to the right of the observed value of our test statistic is greater than $0.05$. In this case, it is (p-value = `r (p_val <- 1-cdf(StudentsT(df = 29),t_obs))`). But we can also ask, where is the cut-off such that the area to the right is *exactly* $0.05$:

--

```{r fig.height = 2, fig.width = 4, out.height = "300px", out.width = "600px"}
ggplot() + 
  geom_pdf(d = StudentsT(df = 29)) +
  geom_vline(aes(xintercept = quantile(StudentsT(df = 29), 0.95), color = "xbar"), linetype = "dashed") +
  scale_x_continuous("", 
                     breaks = c(0,quantile(StudentsT(df = 29), 0.95)),
                     labels = c(0,round(quantile(StudentsT(df = 29), 0.95), digits = 3))) +
  scale_y_continuous("", expand = expand_scale(0, c(0,0.1))) +
  scale_color_manual("", values = c("blue"), 
                     labels = c(bquote(t[.(sample_size - 1)~","~0.05]))) + 
  theme(panel.grid = element_blank(),
        axis.text.y = element_blank(),
        axis.line.x = element_line())
```

I.e. we would reject if test statistic is greater than `r (t_crit <- round(quantile(StudentsT(df = 29), 0.95), digits = 3))`. So the rejection region on the test statistic scale is $[`r t_crit`, \infty)$.

---

This is not super useful in the sense that we do not have a good understanding of what a test statistic of, say, $3$ is. 

Fortunately, we can do even better! We can translate this back onto the $\bar{X}$ scale. 

$T_{\text{obs}} = `r t_crit`$, so $\frac{\bar{x}_{\text{obs}} - 5}{\widehat{\text{SD}}(\bar{X})} = `r t_crit`$. I.e. $\bar{x}_{\text{obs}} = `r t_crit`\cdot \widehat{\text{SD}}(\bar{X}) + 5 = `r (x_crit <- round(t_crit * sd(samp[['x']])/sqrt(29) + 5, digits = 3))`$.

We reject when the test statistic is greater than `r t_crit`, which happens when $\bar{x}_{\text{obs}}$ is greater than `r x_crit`. This is something we can actually relate to!

---

So,

* reject when $\text{p-value} < \alpha$

```{r out.width = "400px", out.height = "200px", fig.width = 4, fig.height = 2}
plot_pdf(StudentsT(df = sample_size - 1)) + 
  geom_auc(from = 1.85, alpha = 0.5) +
  geom_vline(xintercept = 1.85, color = "red", linetype = "dashed") + 
  annotate(x = 2.65, y = 0.125, label = "p-value", geom = "text") +
  geom_line(data = data.frame(x = c(2.4, 2.05), y = c(0.085, 0.025)),
            arrow = arrow(length = unit(0.1, "inches"), ends = 'first')) +
  scale_x_continuous("", breaks = c(0, 1.85), 
                     labels = c(0, expression(T[obs]))) +
  scale_y_continuous("", expand = expand_scale(0, c(0,0.1))) +
  theme(panel.grid = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.line.x = element_line())
```

---

So,

* reject when $\text{p-value} < \alpha$

* happens when $\frac{\bar{x}_{\text{obs}} - 5}{\widehat{\text{SD}}(\bar{X})} = T_{\text{obs}} > t_{`r sample_size - 1`, \alpha} = `r t_crit`$
    * so RR for test statistic = $[`r t_crit`, \infty)$

```{r out.width = "400px", out.height = "200px", fig.width = 4, fig.height = 2}
plot_pdf(StudentsT(df = sample_size - 1)) + 
  geom_vline(data = data.frame(),
             aes(xintercept = c(1.85, quantile(StudentsT(df = sample_size - 1),
                                               0.9))),
             color = c("red", "black"),
             linetype = "dashed") + 
  # geom_line(data = data.frame(x = c(2.4, 2.05), y = c(0.085, 0.025)),
  #           arrow = arrow(length = unit(0.1, "inches"), ends = 'first')) +
  scale_x_continuous("", breaks = c(0, 1.85, 
                                    quantile(StudentsT(df = sample_size - 1),
                                             0.9)), 
                     labels = c(0, expression(T[obs]),
                                bquote(t["n-1,"~alpha]))) +
  scale_y_continuous("", expand = expand_scale(0, c(0,0.1))) +
  theme(panel.grid = element_blank(),
        axis.ticks.y = element_blank(),
        axis.text.y = element_blank(),
        axis.line.x = element_line())
```

---

So,

* reject when $\text{p-value} < \alpha$

* happens when $\frac{\bar{x}_{\text{obs}} - 5}{\widehat{\text{SD}}(\bar{X})} = T_{\text{obs}} > t_{n-1, \alpha} = `r t_crit`$
    * so RR for test statistic = $[`r t_crit`, \infty)$

* happens when $\bar{x}_{\text{obs}} > `r x_crit`$
    * so RR for $\bar{x}$ = $[`r x_crit`, \infty)$

Three different scales, but 1-to-1 path between them!